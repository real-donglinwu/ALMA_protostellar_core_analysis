{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "import math\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "# from astropy.utils.data import get_pkg_data_filename\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "from astropy.coordinates import SkyCoord  \n",
    "from astropy.coordinates import FK5  \n",
    "from photutils.aperture import SkyEllipticalAperture, SkyRectangularAperture\n",
    "from photutils.aperture import aperture_photometry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [INPUT] filename of the H2CO fits cube\n",
    "dir_data = '/Users/donglinwu/Desktop/College/Research/'\n",
    "filename = dir_data+'/HOPS198_Data/HOPS198_H2CO_Tp12m7m_Final_Combine_pbcor.fits'\n",
    "\n",
    "hdul = fits.open(filename)\n",
    "hdul.info()\n",
    "\n",
    "hdu = hdul[0]\n",
    "cube_header = hdu.header\n",
    "cube_data = hdu.data\n",
    "\n",
    "## [EDIT] change it according to the axes of the fits file\n",
    "wcs = WCS(cube_header)\n",
    "wcs2d = wcs[0,:,:] \n",
    "wcsv = wcs[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracts the velocity (spectral axis)\n",
    "## [EDIT] change it according to the number of axes of the fits cube\n",
    "crval3 = cube_header['CRVAL3']\n",
    "crpix3 = cube_header['CRPIX3']\n",
    "cdelt3 = cube_header['CDELT3']\n",
    "## v_H2CO: velocity corresponding to each of the channels in meter per second\n",
    "v_H2CO = (crval3 + ((np.arange(cube_data.shape[0]) + 1) - crpix3) * cdelt3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [FUNCTION] extracts noise part of the spectrum\n",
    "def noise_from_spectrum(spectrum, default_noise):\n",
    "    # spectrum: the input spectrum\n",
    "    # default_noise: a list of two indices; spectrum between these two indices is the useful\n",
    "    #                spectrum outside these two indices is pure noise, which will be extracted by this function\n",
    "    #                e.g. default_noise = [20, 80], spectrum[:20] and spectrum[80:] will be extracted and combined \n",
    "    noise = []\n",
    "    for i in range (len(spectrum)):\n",
    "        if i<default_noise[0] or i>default_noise[1]:\n",
    "            if math.isnan(spectrum[i]) == False:\n",
    "                noise.append(spectrum[i])\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Masks the data to exclude the noises\n",
    "\n",
    "## [EDIT]\n",
    "## n_sigma: number of sigma the mask is applied\n",
    "n_sigma = 5\n",
    "## mol_index_noise: a list of two indices that define the range of the noise, see argument default_noise of the function noise_from_spectrum\n",
    "mol_index_noise = [20, 130]\n",
    "\n",
    "# data: spectral cube after the mask is applied\n",
    "# noise: an image of the std noise level\n",
    "data = np.zeros((cube_data.shape[0],cube_data.shape[1],cube_data.shape[2]),dtype=float)\n",
    "noise = np.zeros((cube_data.shape[1],cube_data.shape[2]),dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "for xchan in range(cube_data.shape[1]):\n",
    "    for ychan in range(cube_data.shape[2]):\n",
    "        spectrum = cube_data[:,xchan,ychan]\n",
    "        vec_noise = noise_from_spectrum(spectrum, [mol_index_noise[0],mol_index_noise[1]])\n",
    "        noise[xchan,ychan] = np.std(vec_noise)\n",
    "        Mask = np.greater(spectrum,n_sigma*np.std(vec_noise))\n",
    "        data[:,xchan,ychan] = spectrum*Mask.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [INPUT] Imports the fits file for the mass of the outflow -> used as contours in plots\n",
    "hdu_outflow = fits.open(dir_data+'/HOPS198/outflow/HOPS198_12CO_outflow_mass_order5_nrect_20.fits')[0]\n",
    "M_outflow_pixel = hdu_outflow.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [INPUT] Imports the fits file for the continuum -> used as contours in plots\n",
    "\n",
    "from reproject import reproject_exact\n",
    "hdu_cont = fits.open(dir_data+'HOPS198_Data/HOPS-198_Continuum_natural.thres0.11mJy.image.pbcor.fits')[0]\n",
    "continuum, footprint2 = reproject_exact(hdu_cont, wcs[0,:,:])\n",
    "# continuum = hdu_cont.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [INPUT] Imports the fits file for the disk -> used as contours in plots\n",
    "hdu_disk = fits.open(dir_data+'/HOPS198_Data/VANDAM/HOPS-198_cont_robust2.pbcor.fits')[0]\n",
    "\n",
    "\n",
    "## [EDIT] change it according to the axes of the fits file\n",
    "disk_data_original = hdu_disk.data[0,0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [OPTIONAL] \n",
    "## If the fits file of the disk has different resolution and WCS axes as the fits file of the other data, use this section\n",
    "## This section finds the vertices of the contours of the disks under the WCS axes of the H2CO fits cube\n",
    "\n",
    "## [EDIT] Change the levels of the corresponding contours \n",
    "\n",
    "plt.imshow(disk_data_original,origin='lower')\n",
    "contour1 = plt.contour(disk_data_original, cmap='inferno',levels=[0.2*np.nanmax(disk_data_original)])\n",
    "contour2 = plt.contour(disk_data_original, cmap='inferno',levels=[0.5*np.nanmax(disk_data_original)])\n",
    "contour_data1 = contour1.collections[0].get_paths()\n",
    "contour_data2 = contour2.collections[0].get_paths()\n",
    "plt.xlim(400,600)\n",
    "plt.ylim(400,600)\n",
    "\n",
    "from astropy.wcs.utils import pixel_to_skycoord, skycoord_to_pixel\n",
    "for path in contour_data1:\n",
    "    # print(path.vertices)\n",
    "    coords_contour1_disk_ALMA = skycoord_to_pixel(pixel_to_skycoord(path.vertices[:,0], path.vertices[:,1], WCS(hdu_disk.header)), WCS(hdu_cont.header)[:,:])\n",
    "for path in contour_data2:\n",
    "    # print(path.vertices)\n",
    "    coords_contour2_disk_ALMA = skycoord_to_pixel(pixel_to_skycoord(path.vertices[:,0], path.vertices[:,1], WCS(hdu_disk.header)), WCS(hdu_cont.header)[:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding locations where there are two peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [EDIT] \n",
    "## channel_min, channel_max: indices that define the range of channels in which the algorithm looks for the peaks\n",
    "##                           it should take into consideration of the noises as well as contamination from the outflow\n",
    "channel_min, channel_max = 58, 85\n",
    "\n",
    "## height_peak: the minimum height required for the peak\n",
    "##              should be adjusted according to the signal levels as well as signal-to-noise ratio\n",
    "height_peak = 0.02\n",
    "\n",
    "\n",
    "## bright_peak, dim_peak: a 2d array that records the velocity of the brighter or dimmer peak from the two peaks for spectrum of each of the pixels (in m/s)\n",
    "bright_peak = np.zeros(shape=(cube_data.shape[2],cube_data.shape[1]))\n",
    "dim_peak = np.zeros(shape=(cube_data.shape[2],cube_data.shape[1]))\n",
    "\n",
    "## delta_vpeaks: a 2d array that records the velocity of the brighter peak subtracted from the velocity of the dimmer peak (in m/s)\n",
    "##               if the blueshifted peak is brighter, this should be positive\n",
    "deltav_peaks = np.zeros(shape=(cube_data.shape[2],cube_data.shape[1]))\n",
    "\n",
    "\n",
    "for xchan in range(cube_data.shape[1]):\n",
    "    for ychan in range(cube_data.shape[2]):\n",
    "        peaks, heights = find_peaks(data[:, ychan, xchan], height=height_peak)\n",
    "        heights = heights['peak_heights']\n",
    "        peaks_new, heights_new = [], []\n",
    "        for peak, height in zip(peaks, heights):\n",
    "            if channel_min <= peak <= channel_max:\n",
    "                peaks_new.append(peak)\n",
    "                heights_new.append(height)\n",
    "        peaks_new, heights_new = np.array(peaks_new), np.array(heights_new)\n",
    "        if len(peaks_new) > 1:\n",
    "            try:\n",
    "                peak_first, height_first = peaks_new[np.argmax(heights_new)], heights[np.argmax(heights_new)]\n",
    "                heights_f_removed = np.copy(heights_new)\n",
    "                heights_f_removed[heights_f_removed == height_first] = -np.inf\n",
    "                peak_second, height_second = peaks_new[np.argmax(heights_f_removed)], heights[np.argmax(heights_f_removed)]\n",
    "                bright_peak[ychan, xchan] = v_H2CO[peak_first]\n",
    "                dim_peak[ychan, xchan] = v_H2CO[peak_second]\n",
    "                deltav_peaks[ychan, xchan] = v_H2CO[peak_second] - v_H2CO[peak_first]\n",
    "            except:\n",
    "                print(np.argmax(heights_new), heights[np.argmax(heights_new)])\n",
    "\n",
    "deltav_peaks[deltav_peaks == 0] = np.nan\n",
    "bright_peak[bright_peak == 0] = np.nan\n",
    "dim_peak[dim_peak == 0] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the velocity of the brighter peak\n",
    "\n",
    "semi_a = 150\n",
    "bright_peak[bright_peak == 0] = np.nan\n",
    "plt.imshow(bright_peak/1000, origin='lower', vmin=4.8, vmax=7)\n",
    "plt.colorbar(label=r'$v_{\\text{bright}}$ [km/s]')\n",
    "\n",
    "plt.xlim(semi_a, 448-semi_a)\n",
    "plt.ylim(semi_a, 448-semi_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the velocity of the brighter peak subtracted from the velocity of the dimmer peak\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "plt.figure()\n",
    "plt.subplot(projection=wcs2d)\n",
    "\n",
    "plt.imshow(deltav_peaks/1000, origin='lower',vmin=-0.6,vmax=0.6,cmap='coolwarm')\n",
    "plt.colorbar(label=r'$\\Delta v$ [km/s]')\n",
    "\n",
    "## [EDIT] contours of the outflow, continuum and the disk data\n",
    "plt.contour(np.greater(M_outflow_pixel, 0.3*np.nanstd(M_outflow_pixel)), cmap=mcolors.ListedColormap(['cyan']))\n",
    "plt.contour(continuum, levels=[0.05*np.nanmax(continuum)],cmap='Reds')\n",
    "plt.plot(coords_contour1_disk_ALMA[0],coords_contour1_disk_ALMA[1], color='black')\n",
    "plt.plot(coords_contour2_disk_ALMA[0],coords_contour2_disk_ALMA[1], color='white')\n",
    "\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('DEC')\n",
    "\n",
    "## [EDIT] the size of the plot generated\n",
    "semi_a = 150\n",
    "plt.xlim(semi_a, 448-semi_a)\n",
    "plt.ylim(semi_a, 448-semi_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the difference in velocity of the two peaks, for pixels where the blueshifted peak is brighter\n",
    "\n",
    "\n",
    "\n",
    "## deltav_peaks_pos: difference in velocity of the two peaks, for pixels where the blueshifted peak is brighter\n",
    "deltav_peaks_pos = np.copy(deltav_peaks)/1000\n",
    "deltav_peaks_pos[deltav_peaks <= 0] = np.nan\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "fig = plt.figure()\n",
    "plt.subplot(projection=wcs2d)\n",
    "im = plt.imshow(deltav_peaks_pos, origin='lower',vmin=0.3,vmax=0.6)\n",
    "plt.colorbar(im, label=r'$\\Delta v$ [km/s]')\n",
    "\n",
    "## [EDIT] contours of the outflow, continuum and the disk data\n",
    "plt.contour(np.greater(M_outflow_pixel, 0.3*np.nanstd(M_outflow_pixel)), cmap=mcolors.ListedColormap(['red']))\n",
    "plt.contour(continuum, levels=[0.05*np.nanmax(continuum)],cmap='Reds')\n",
    "plt.plot(coords_contour1_disk_ALMA[0],coords_contour1_disk_ALMA[1], color='black')\n",
    "plt.plot(coords_contour2_disk_ALMA[0],coords_contour2_disk_ALMA[1], color='white')\n",
    "\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('DEC')\n",
    "\n",
    "## [EDIT] the size of the plot generated\n",
    "semi_a = 150\n",
    "plt.xlim(semi_a, 448-semi_a)\n",
    "plt.ylim(semi_a, 448-semi_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writes the difference in velocity of the two peaks, for pixels where the blueshifted peak is brighter, into a fits file\n",
    "\n",
    "\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "hdu_output = fits.PrimaryHDU()\n",
    "hdu_output.data = deltav_peaks_pos\n",
    "\n",
    "for i in range(len(list(hdu.header.keys()))):\n",
    "    key = list(hdu.header.keys())[i]\n",
    "    if '3' not in key and 'COMMENT' not in key and 'HISTORY' not in key:\n",
    "        # print(key)\n",
    "        hdu_output.header.update({key:hdu.header[key]})\n",
    "\n",
    "hdu_output.header.update({'NAXIS':2})\n",
    "\n",
    "# hdu_output.writeto('./HOPS198_H2CO_two_peaks_deltav_blue_brighter.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates a mask, which only includes pixels where the spectrum shows two peaks and the blueshifted peak is brighter\n",
    "\n",
    "mask_deltav_pos = np.copy(deltav_peaks_pos)\n",
    "mask_deltav_pos[np.isnan(mask_deltav_pos) == False] = 1\n",
    "plt.imshow(mask_deltav_pos, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a two layer radiative transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = const.h.value\n",
    "k = const.k_B.value\n",
    "pi = math.pi\n",
    "\n",
    "nu_o = cube_header['RESTFRQ']  #rest Frequency of H2CO(2-1) transition from header (in Hz)\n",
    "bmaj = cube_header['BMAJ'] * 3600. #beam major axis (in arcsec)\n",
    "bmin = cube_header['BMIN'] * 3600. #beam major axis (in arcsec)\n",
    "dx = cube_header['CDELT1'] # length of pixel (in degrees)\n",
    "dy = cube_header['CDELT2'] # width of pixel (in degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [EDIT]\n",
    "## level_continuum: the level that defines the \"region of continuum\", to which the radiative transfer model is applied, from the continuum data\n",
    "##                  only pixels brighter than this level are included\n",
    "## [REQUIRED]       the level is chosen so that the size of this region is approximately the same as the same of the beam\n",
    "## note: there are various other ways to select a \"region of continuum\" \n",
    "level_continuum = 8.25e-3\n",
    "\n",
    "\n",
    "## H2CO_cont: a 2d array which labels the pixels that are included in the \"region of continuum\"\n",
    "## H2CO_continuum: the average spectrum of the \"region of continuum\"\n",
    "##                 this will be the spectrum to which the radiative transfer model is applied\n",
    "\n",
    "\n",
    "H2CO_continuum = np.zeros(hdu.data.shape[0])\n",
    "H2CO_cont = np.zeros(shape=(hdu.data.shape[1], hdu.data.shape[2]))\n",
    "n_pixels = 0\n",
    "loc_cont = []\n",
    "for i in range(-10, 10):\n",
    "    for j in range(-10, 10):\n",
    "        if np.max(continuum[224+i, 224+j]) >= level_continuum:\n",
    "            n_pixels += 1\n",
    "            # H2CO_continuum += data[:, 224+i, 224+j]\n",
    "            H2CO_continuum += hdu.data[:, 224+i, 224+j]\n",
    "            H2CO_cont[224+i, 224+j] = 1\n",
    "            loc_cont.append((i,j))\n",
    "print(n_pixels)\n",
    "H2CO_continuum = H2CO_continuum/n_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the continuum data and the \"region of continuum\" \n",
    "\n",
    "plt.subplot(projection=wcs2d)\n",
    "plt.imshow(continuum)\n",
    "plt.contour(H2CO_cont, cmap='Accent')\n",
    "# plt.contour(loc_two_peaks)\n",
    "plt.xlim(200,448-200)\n",
    "plt.ylim(200,448-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes the ratio of the area of the \"region of continuum\" selected to the area of the beam\n",
    "## Ideally, it should be close to 1\n",
    "\n",
    "A_continuum = abs(n_pixels*dx*3600*dy*3600)\n",
    "A_beam = pi*bmaj*bmin/4\n",
    "print(A_continuum/A_beam) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [FUNCTION] Converts the intensity Jy/beam to brightness temperautre (K)\n",
    "\n",
    "def T_mb(I, nu, bmaj, bmin):\n",
    "    # This function changes the intensity from Jy/beam to brightness temperautre (K)\n",
    "    # I: intensity in Jy/beam\n",
    "    # nu: frequency in Hz\n",
    "    # bmin: beam minor axis (arcsec) \n",
    "    # bmax: beam major axis (arcsec)\n",
    "    return 1.222*1e6*I/(((nu/1e9)**2)*bmaj*bmin) #K/beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## T_H2CO_cont: intensity (in brightness temperature) of the average H2CO spectrum of the region selected\n",
    "T_H2CO_cont = T_mb(H2CO_continuum, nu_o, bmaj, bmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [OPTIONAL] \n",
    "## Computes the H2CO spectrum and std for each of the pixel in the region selected\n",
    "## Not useful in most case\n",
    "\n",
    "# vec_T_H2CO_cont = np.zeros(shape=(n_pixels,hdu.data.shape[0]))\n",
    "# vec_T_H2CO_std = np.zeros(shape=hdu.data.shape[0])\n",
    "# for (i,j), index in zip(loc_cont, range(n_pixels)):\n",
    "#     vec_T_H2CO_cont[index] = T_mb(hdu.data[:, 224+i, 224+j], nu_o, bmaj, bmin)\n",
    "# for index_v in range(hdu.data.shape[0]):\n",
    "#     vec_T_H2CO_std[index_v] = np.std(np.transpose(vec_T_H2CO_cont)[index_v])\n",
    "# plt.plot(v_H2CO, vec_T_H2CO_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [PLOTS] plots the average H2CO spectrum (in brightness temperature)\n",
    "## Note: this is used to find the range of channels that the fit to the model should be applied to\n",
    "##       the width of the spectrum should not be too large (if it is large, it is likely that there is contamination which should be excluded)\n",
    "##       it is also used to identify the three important channels in this spectrum: the two peaks and the trough between\n",
    "##       sometimes, these three points are assigned extra weight in the fit \n",
    "\n",
    "plt.plot(v_H2CO/1000, T_H2CO_cont)\n",
    "# plt.plot(v_H2CO[:35]/1000, T_H2CO_cont[:35])\n",
    "# plt.plot(v_H2CO[110:]/1000, T_H2CO_cont[110:])\n",
    "plt.plot(v_H2CO[60:82]/1000, T_H2CO_cont[60:82], color='red')\n",
    "plt.scatter(v_H2CO[66]/1000, T_H2CO_cont[66])\n",
    "plt.scatter(v_H2CO[69]/1000, T_H2CO_cont[69])\n",
    "plt.scatter(v_H2CO[75]/1000, T_H2CO_cont[75])\n",
    "plt.xlabel(r'$v_{\\text{LSR}}$ [km/s]')\n",
    "plt.ylabel(r'$T_b$ [k]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [FUNCTION] This function defines the model\n",
    "##            It outputs the expected brightness temperature according to the model\n",
    "##            The model can be found at: DOI 10.1086/323854\n",
    "\n",
    "## J_b: the background temperature: the CMB temperature\n",
    "J_b = 2.725\n",
    "\n",
    "## phi: fraction of the telescope beam area filled by the source (the source from the disk data)\n",
    "phi = 0.5\n",
    "\n",
    "def T_B_fit(v, v_sys, J_f, J_r, T_c, v_in, sigma, tau_0):\n",
    "    # v: velocity of the channel evaluated\n",
    "    # v_sys: system velocity, or velocity of the cloud; it can be a free parameter or a fixed parameter\n",
    "    # J_f: temperature of the front layer\n",
    "    # J_r: temperature of the rear layer\n",
    "    # T_c: the blackbody temperature at the frequency of the line\n",
    "    # v_in: infall velocity\n",
    "    # sigma: velocity dispersion of the line\n",
    "    # tau_0: optical thickness of the line\n",
    "    \n",
    "    T_o = h*nu_o/k\n",
    "    J_c = T_o/(np.exp(T_o/T_c)-1)\n",
    "    J_cr = phi*J_c + (1-phi)*J_r\n",
    "    tau_f = tau_0*np.exp(-pow(v - v_in - v_sys,2)/(2*pow(sigma,2)))\n",
    "    tau_r = tau_0*np.exp(-pow(v + v_in - v_sys,2)/(2*pow(sigma,2)))\n",
    "    return (J_f - J_cr)*(1-np.exp(-tau_f))+(1-phi)*(J_r-J_b)*(1-np.exp(-tau_r-tau_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT REMARK: The following part is preliminary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [EDIT]\n",
    "## index_low, index_high: indices that define the range of channels that the fit to the model should be applied to\n",
    "##                        it is important to exclude contamination from the outflow using these two indices\n",
    "index_low,index_high = 60, 82\n",
    "\n",
    "\n",
    "## [FUNCTION]\n",
    "## Calculates the sum of difference between the expected surface temperature of the model with a given set of parameters\n",
    "##            with the actual surface temperature measured by the data\n",
    "##            \n",
    "\n",
    "indices_extra_weight = [66, 69, 75]\n",
    "extra_weight = 3\n",
    "\n",
    "def func_fit(v_sys, J_f, J_r, T_c, v_in, sigma, tau_0):\n",
    "    vdata, Tdata = v_H2CO, T_H2CO_cont\n",
    "    mean_square = np.zeros(len(vdata))\n",
    "    T_fit = T_B_fit(vdata, v_sys, J_f, J_r, T_c, v_in, sigma, tau_0)\n",
    "    for i in range(index_low,index_high):\n",
    "        mean_square[i] = pow(abs(T_fit[i]-Tdata[i]), 2) \n",
    "    if J_f < J_r:\n",
    "        return sum(mean_square) + sum([mean_square[index_w] for index_w in indices_extra_weight])*extra_weight\n",
    "    else:\n",
    "        return sum(mean_square) + sum([mean_square[index_w] for index_w in indices_extra_weight])*extra_weight + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Runs MCMC to fit the radiative transferl model to the observed surface temperature\n",
    "## Uses uniform prior\n",
    "## The system velocity can be a free parameter or a fixed parameter: if it is fixed, the model sometimes performs better\n",
    "\n",
    "## [EDIT]\n",
    "## Initial guess for the parameters: system velocity, J_f, J_r, T_c, infall velocity, velocity dispersion, optical thickness\n",
    "initial_params = [5600, 29, 40, 30, 350, 260, 0.1]\n",
    "bounds = np.array([\n",
    "    [5595, 5605],   # v_sys\n",
    "    [   10,  80],   # J_f\n",
    "    [   10,  80],   # J_r\n",
    "    [   10,  100],   # T_c\n",
    "    [   0, 800],   # v_in\n",
    "    [   0, 600],   # sigma\n",
    "    [   0,    0.2],   # tau_0\n",
    "])\n",
    "n_dim = len(initial_params)\n",
    "\n",
    "## Define a uniform prior \n",
    "def log_prior(params):\n",
    "    low, high = bounds[:, 0], bounds[:, 1]\n",
    "    if np.any(params < low) or np.any(params > high):\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "## Define the cost function\n",
    "def log_likelihood(params):\n",
    "    cost = func_fit(*params)\n",
    "    return -0.5 * cost\n",
    "\n",
    "## Define the posterior distribution\n",
    "def log_posterior(params):\n",
    "    lp = log_prior(params)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(params)\n",
    "\n",
    "## Set up the sampler\n",
    "\n",
    "## [EDIT]\n",
    "## Number of walkers: the number of parallel MCMC chains exploring parameter space.\n",
    "n_walkers = 64  \n",
    "\n",
    "## Number of steps: how many iterations each walker will take (the length of each chain).\n",
    "n_steps = 5000  \n",
    "\n",
    "## Step size: controls the scale of the initial perturbation around your starting guess.\n",
    "##            A value of 0.1 means each walker is placed in a Gaussian “ball” of radius ~10% of initial_params.\n",
    "step_size = 0.1  \n",
    "\n",
    "\n",
    "pos = initial_params + step_size * np.array(initial_params) * np.random.randn(n_walkers, n_dim)\n",
    "sampler = emcee.EnsembleSampler(n_walkers, n_dim, log_posterior)\n",
    "sampler.run_mcmc(pos, n_steps, progress=True)\n",
    "samples = sampler.get_chain(flat=True)\n",
    "\n",
    "## Plot the histograms of the distribution and store the means and highest peaks of the distributions of the parameters\n",
    "param_names = [\"v_sys\",\"J_f\",\"J_r\",\"T_c\",\"v_in\",\"sigma\",\"tau_0\"]\n",
    "\n",
    "## param_mean: means of the parameters\n",
    "## param_peak: highest peak of the distributions of the parameters\n",
    "param_mean, param_peak = [], []\n",
    "\n",
    "for i, name in enumerate(param_names):\n",
    "    param_samples = samples[:, i]\n",
    "    mean, std = param_samples.mean(), param_samples.std()\n",
    "    param_mean.append(mean)\n",
    "    print(f\"{name:6s} → Mean = {mean:.2f}, Std = {std:.2f}\")\n",
    "\n",
    "    # histogram + peak\n",
    "    low, high = bounds[i]\n",
    "    counts, edges = np.histogram(param_samples,\n",
    "                                 bins=30,\n",
    "                                 density=True,\n",
    "                                 range=(low, high))\n",
    "    centers = 0.5*(edges[:-1] + edges[1:])\n",
    "    peak_loc = centers[np.argmax(counts)]\n",
    "    param_peak.append(peak_loc)\n",
    "\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    plt.hist(param_samples,\n",
    "             bins=30,\n",
    "             density=True,\n",
    "             range=(low, high),\n",
    "             alpha=0.6)\n",
    "    plt.title(f\"{name}  (peak @ {peak_loc:.2f})\")\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the model spectrum using peaks of the distributions of parameters and compares it with the measured spectrum \n",
    "## [IMPORTANT] Sometimes, the spectrum using the highest peak might deviate in terms of height.\n",
    "##             This is often due to the optical depths being weakly constrained (sometimes two peaks are shown in the distribution).\n",
    "##             The mean optical depth along with the highest peak of the other parameters often produce the best spectrum.\n",
    "\n",
    "\n",
    "T_H2CO_fit = T_B_fit(v_H2CO,*param_peak) \n",
    "T_H2CO_adjusted = T_B_fit(v_H2CO,*param_peak[:len(param_peak)-1], param_mean[-1]) \n",
    "plt.plot(v_H2CO, T_H2CO_cont, label='Observed')\n",
    "plt.plot(v_H2CO, T_H2CO_fit, label='Model (all peaks)')\n",
    "plt.plot(v_H2CO, T_H2CO_adjusted, label='Model (mean for optical depth)')\n",
    "plt.ylabel('T [K]')\n",
    "plt.xlabel('v [m/s]')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
